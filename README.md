## 2023gsc_TaiyuOzawa-

# 2023年度古橋ゼミ卒論用レポジトリ


2023年度 ゼミ論文/卒業論文

青山学院大学 地球社会共生学部 地球社会共生学科

小澤太佑/Ozawa Taiyu

学生番号 1A120047

指導教員 古橋大地 教授

© Furuhashi Laboratory/Taiyu Ozawa, CC BY 4.0

# Title：画像生成AIによる、ゼミ用画像生成におけるゼミワードリストの構築

## Abstract：文章全体の要約
本論文では、グローバル化かつ幅広い活動を行っている「古橋ゼミ」の活動をより視覚的に分かりやすくするため、画像生成AIにて画像を生成する際に用いる「ワード」を「ゼミワードリスト」化することを目的としている。ここで論じるゼミワードリストとは、古橋ゼミに関連する、例えばドローンや位置情報ゲームなどといった様々なワードを、項目ごとに分け、各データを順序を付けて格納した一覧のことを指す。

2024年1月の現状の画像生成AIにおいては、単に単語を羅列するだけではイメージと異なる画像が生成されることが多いため、上記で定義した「ワードリスト」を用いることで、一定のイメージに近い画像を生成することを可能にする。また「Methods」の章では、使用する画像生成AIや、prompt生成に用いる自然言語処理AIの紹介を元に、研究の進行方向について記載し、「Results」にて実際に作成した「ワードリスト」を記載した。


## Introdunction：
近年、自然言語によって構成される「prompt」に応じて、文章や画像、動画を生成するAIモデルが急激に発展している。画像生成AIに関しては、2022年7月13日に「Midjourney」と呼ばれる画像生成AIのオープンベータ版がリリースされ、その他にも「stable diffusion」や「Novel AI」といったモデルが存在し、同じpromptを使用したとしても、モデルによって生成される画像はモデルによって大きく異なる。

本論文では、さきに紹介した、画像生成AIの一種である「Midjourney」を用いて、ゼミの様々な場面で活用することができる画像を、精度高く生成できるよう、promptにおける中枢となるワードを、ゼミワードリスト化し、誰でも簡単に画像を生成できるようにすることが目的とする。

画像生成AIには、ラフスケッチのような画像をより完成度の高い画像に仕上げる「image to image」と呼ばれるものと、Promptと呼ばれる指示文章から画像を生成する「text to image」と呼ばれるものがあるが、今回は後者の画像生成AIを活用する。「text to image」では、GAN（敵対的生成ネットワーク）と呼ばれる、2つのネットワークを競い合わせることで生成する画像の精度を高める仕組みや、拡散モデルといった、元データに徐々にノイズを加えたり、逆にノイズを消去するプロセスを経て新しいデータを生み出すなど、事前に学習されたモデルを活用し、文字情報からクリエイティビティ豊かな画像を生み出す（松川瞬, 真田博文, & 稲垣潤. (2023). 画像変換 AI における画像の情報量に依る生成画像精度の非対称性について.）。

画像生成AIが登場して、まだ長い時間が経っていない現在では、学業においてはあまり用いられていないが、今後画像生成AIで作られる画像はより発達、一般化し、さまざまな場面で使用されると考えている。

それを踏まえ、この仕組みを用いて私が作成したいのは、、プレゼンテーションやゼミの紹介動画、場合によってはゼミのイメージ画像として用いることのできる、バラエティ豊かかつ、さまざまなシチュエーションに可能が画像を生み出すことができる、「ゼミワードリスト」を作成することである。青山学院大学 古橋研究室は、同大学の他ゼミに比べて外部への露出が非常多い。そこで、どんなシチュエーションでも活用可能な画像を、即座に、簡単に生成することができる、中枢ワードリストを作成することで、本ゼミでの活動内容や雰囲気、実績がより他のコミュニティ、人々が認識しやすくなると考えた。また、その内容は完全なる独自的なものではなく、他の分野・業界にも転用可能な普遍的な項目も非常に多いと考えている。

promptではなく「ワードリスト」を作成する理由としては、画像生成AIが日々目まぐるしい変化と成長を遂げる中で、それに呼応してpromptも大きく変化しており、どうしても変数になり得てしまうと考えたからである。一方でワードは、どんなに画像生成AIや最適とされるpromptが変化しようと、必ず必要かつ重要となる普遍的な定数となりうると考え、今回のこの「ワード」に絞って研究を進めたいと考えた。

研究の方法としては、Discordというチャットサービスプラットフォームを介して画像を生成する「Midjourney」において、自然言語処理AI「ChatGPT-4」でpromptを作成しながら、各シチュエーションにおいて最適なワードを発見し、リスト化を行う。

格納場所：https://docs.google.com/spreadsheets/d/1GLylHkcSu2AUoVp84yU7rH-v1CkUVd7WUmREGl45T1I/edit#gid=804927239

## Methods：（研究に用いた方法、手法、ストラテジーについて記述する。）

本論文において、画像を生成する方法としては、作成したい絵の説明を自然言語処理モデルである「ChatGPT」に日本語のpromptを打ち込み、Midjourneyに使用するpromptを生成することを前提にする。
そのためゼミワードを使用するタイミングは、作成したい絵のpromptを、ChatGPTを用いて作成するタイミングとなる。

例：大学のキャンパス（相模原キャンパス）で、学生がドローンを飛ばしているジブリ風の画像を生成したい

使い方：該当する「相模原キャンパス」と「ドローン」のワード部分を、本ワードリストのワードを用いる

ChatGPTにおいて、画像生成用のpromptを生成するためのprompt：薄い黄色のモダン調の大学のキャンパスで、私服の、20歳の日本人学生が白く、足とプロペラが4つずつで、下部にカメラのあるドローンを飛ばしているジブリ風の画像

また、ゼミの中枢ワードに関しては、メディウムの頻出ワードをリストアップしたものをメインに行った。
![スクリーンショット 2023-11-28 11 10 41](https://github.com/furuhashilab/2023gsc_TaiyuOzawa-/assets/87391164/ed130e75-aac7-4a7e-8d2a-9baaf14feb0c)

進行方向は以下の通りである。
1.出力したい画像のpromptを日本語で自分で考案する
2.ChatGPT-4で英語の画像生成用promptを生成
3.Midjourneyで画像を出力
4.改善の仮説をたて、再度1から進行する

<img width="819" alt="スクリーンショット 2023-11-28 11 11 39" src="https://github.com/furuhashilab/2023gsc_TaiyuOzawa-/assets/87391164/923d038b-5b78-4d08-94fd-7f18560ed64c">

## Results:

本ゼミでの活動が、単語からのイメージをよりコンパクトにした内容の場合は特に、別の言葉を用いる必要があることが分かった。例えば国際会議の画像を出力すると、巨大空間で、全員がスーツを着てプレゼンを視聴している画像が出力されることが多い。そこで、「プロジェクターを用いて発表を行なっている様子」と指定すると、イメージに近い画像が出力される確率が非常に高まる。

なお、本研究の課題は以下の通りである。

1.ワード発見の効率について
元は、自然言語処理AIとの対話によりワードの精度を高める予定であった。しかし実際に試してみると、我々が感覚的な部分で「これがゼミっぽい」という内容が、自然言語処理AIでは反映されず、最終的には「ワードの考案」に関しては自分で考える方が効率が良い結果となった。しかしこの方法では、作成者の感覚に大きく左右されるという点と、一つのワードを作成するのに多くの時間を要し、かつ定量的な判断ができないという課題がある。

2.複数要素を組み込む場合について
上記リストの3つ以上の項目を含んだ画像を生成する場合、いくつかの要素が反映されない絵が生成される場合が殆どであった。その場合、より簡潔なワードを生成したり、prompt自体の工夫が必要になると考えており、本論文ではそこまでの解決法には至ることが出来なかった。

## Conclusion

画像生成AIに関しては、今後教育やビジネスの現場においても更なる導入が期待されるが、現状、本ゼミ内においては、活用されている場面はほぼないに等しい状態となっている。そこで、「誰でも簡単にゼミで活用できる画像を生成する」ことができるよう、「ゼミワードリスト」を作成した。
しかし最終的には、「誰かが使用する」という行動が伴うことでやっと意味をなす研究である。そのため、この研究内容の認知度を広めることや、「引き継いでもらう」ことで、ゼミ内での認知度を広めつつも、より使いやすい内容に改善を繰り返すことが重要だと考える。

## 謝辞
本研究を進めるにあたり古橋教授をはじめ、多くの方々より多大な助言を賜りました。厚く感謝を申し上げます。


## 参考文献
https://docs.google.com/spreadsheets/d/1GLylHkcSu2AUoVp84yU7rH-v1CkUVd7WUmREGl45T1I/edit#gid=0


